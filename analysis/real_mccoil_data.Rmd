---
title: "REAL McCOIL Data"
author: "Aris Paschalidis"
date: "`r format(Sys.time(), '%B %Y')`"
output:
  html_document:
    highlight: pygments
    toc: true
    toc_float: true
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
# Here, we set default options for our markdown file
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
# Change the way tibble prints so only prints 5 extra columns
options(tibble.max_extra_cols = 5)

# Function to determine if pbapply is installed. If it is installed, it will
# display a progress bar
list_apply <- function(x, fun, ...) {
  if (requireNamespace("pbapply", quietly = TRUE)) {
    pbapply::pblapply(x, fun, ...)
  } else {
    lapply(x, fun, ...)
  }
}

# Define booleans to determine whether certain code chunks should be run.
run_real <- FALSE
read_pf6k <- FALSE

library(coiaf)
library(ggplot2)
library(patchwork)
```

In this analysis file, we run our COI algorithm on a collection of real data
obtained from the Pf3k Malaria project. Additionally, we compare the results of
our algorithm with the current state of the art model for predicting COI -- REAL
McCOIL.

## Run Real Data

```{r read data}
# Path to data
path <- "~/Desktop/Malaria/COI data/"

# Read in the real data and the REAL McCOIL COI predictions
rmcl_wsafs <- readRDS(paste0(path, "RMCL_wsafs_unique.rds"))
rmcl_coi_out <- readRDS(paste0(path, "RMCL_coi_out.rds")) %>%
  tibble::as_tibble() %>%
  dplyr::mutate(dplyr::across(c(file, name), as.character)) %>%
  dplyr::rename(rmcl = COI) %>%
  dplyr::rename(rmcl_025 = COI_025) %>%
  dplyr::rename(rmcl_975 = COI_975)
```

```{r run method}
run_method <- function(sample_name, input, fn, coi_method) {
  tryCatch(
    coi <- rlang::exec(
      fn,
      data = input,
      data_type = "real",
      coi_method = coi_method,
      bin_size = 50
    ),
    error = function(e) {
      rlang::inform(glue::glue("Error for sample { sample_name }"))
      return(NaN)
    }
  )

  if (fn == "compute_coi") coi$coi else coi
}
```

Run our data, set it up in an ideal format and save the data sets as .rds files.

```{r run data, eval = run_real}
raw_predictions <- lapply(
  cli::cli_progress_along(seq_along(rmcl_wsafs), "Computing predictions"),
  function(x) {
    sample <- rmcl_wsafs[[x]]
    plaf <- colMeans(sample, na.rm = T)

    # For each sample run the estimation functions
    coi_region <- lapply(
      cli::cli_progress_along(seq_len(nrow(sample)), "Estimating COI"),
      function(i) {
        sample_name <- rownames(sample)[i]
        wsaf <- sample[i, ]
        input <- tibble::tibble(wsaf = wsaf, plaf = plaf) %>% tidyr::drop_na()

        dis_var <- run_method(sample_name, input, "compute_coi", "variant")
        dis_freq <- run_method(sample_name, input, "compute_coi", "frequency")
        cont_var <- run_method(sample_name, input, "optimize_coi", "variant")
        cont_freq <- run_method(sample_name, input, "optimize_coi", "frequency")

        list(
          dis_var = dis_var,
          dis_freq = dis_freq,
          cont_var = cont_var,
          cont_freq = cont_freq
        )
      }
    )

    coi_region <- coi_region %>%
      unlist() %>%
      split(., names(.))

    # Prediction tibble
    pred <- tibble::tibble(
      name = rownames(sample),
      dis_var = coi_region$dis_var,
      dis_freq = coi_region$dis_freq,
      cont_var = coi_region$cont_var,
      cont_freq = coi_region$cont_freq,
      file = names(rmcl_wsafs)[x]
    )

    # Summarize over the 5 rmcl runs
    rmcl_outputs <- rmcl_coi_out %>%
      dplyr::filter(stringr::str_detect(file, names(rmcl_wsafs)[x])) %>%
      dplyr::group_by(name) %>%
      dplyr::summarise(
        rmcl_med = median(rmcl),
        rmcl_025_med = median(rmcl_025),
        rmcl_975_med = median(rmcl_975),
        .groups = "drop"
      )

    # Join the tibbles
    dplyr::full_join(pred, rmcl_outputs, by = "name") %>%
      dplyr::mutate(
        Region = as.numeric(stringr::str_extract(file, "(?<=region_)[:digit:]*")),
        VCF = as.numeric(stringr::str_extract(file, "(?<=vcf_)[:digit:]*"))
      ) %>%
      dplyr::relocate(file, .after = dplyr::last_col())
  }
)
names(raw_predictions) <- names(rmcl_wsafs)

# Set up a tibble with all the information from the runs.
# Summarize over the 10 VCFs
complete_predictions <- raw_predictions %>%
  dplyr::bind_rows() %>%
  dplyr::group_by(name, Region) %>%
  dplyr::summarise(
    dis_var_med = median(dis_var),
    dis_freq_med = median(dis_freq),
    cont_var_med = median(cont_var),
    cont_freq_med = median(cont_freq),
    rmcl_med = median(rmcl_med),
    rmcl_025_med = median(rmcl_025_med),
    rmcl_975_med = median(rmcl_975_med),
    .groups = "drop"
  ) %>%
  dplyr::relocate(Region, .after = dplyr::last_col())

# Save data
saveRDS(
  raw_predictions,
  file = paste0(here::here(), "/analysis/rmcl_raw_predictions.rds")
)
saveRDS(
  complete_predictions,
  file = paste0(here::here(), "/analysis/rmcl_complete_predictions.rds")
)
```

```{r load data, eval = !run_real, include = FALSE}
raw_predictions <- readRDS(paste0(
  here::here(),
  "/analysis/rmcl_raw_predictions.rds"
))
complete_predictions <- readRDS(paste0(
  here::here(),
  "/analysis/rmcl_complete_predictions.rds"
))
```

We want to make sure that we have tested all the patients, so we can look at
our three data structures and ensure that the number of patients is the same
for all.
```{r number of patients}
# According to our predictions
length(unique(complete_predictions$name))

# According to rmcl output
length(unique(rmcl_coi_out$name))

# According to WSAFs
wsafs_patients <- lapply(seq_len(length(rmcl_wsafs)), function(x) {
  rownames(rmcl_wsafs[[x]])
})
wsafs_patients %>%
  unlist() %>%
  unique() %>%
  length()
```
Looking at these values, we can see that for our WSAF matrices and our
predictions the number of patients match. However, our RMCL output has fewer
total patients. We need to be sure to exclude these when we are comparing our
two methods. We end up with `r length(unique(rmcl_coi_out$name))` samples.
```{r exclude patients}
exclude <- setdiff(unique(complete_predictions$name), unique(rmcl_coi_out$name))
compare_data <- complete_predictions %>%
  dplyr::filter(!name %in% exclude) %>%
  dplyr::filter(rmcl_med != 25) %>%
  dplyr::relocate(Region, .after = dplyr::last_col())
```

## Evaluate Our Predictions
We first reshape our data so that we have a single column with our COI
estimates. This involves creating two new additional column to represent the
coi_method and optimization method we used to compute the COI.

```{r pivoting data}
pivot_data <- compare_data %>%
  tidyr::pivot_longer(
    cols = dplyr::starts_with(c("dis", "cont")),
    names_to = c(".value", "coi_method"),
    names_pattern = "(.*)_(.*)_.*"
  ) %>%
  tidyr::pivot_longer(
    cols = dplyr::any_of(c("dis", "cont")),
    names_to = "optimization",
    values_to = "COI",
    values_drop_na = TRUE
  ) %>%
  dplyr::relocate(
    dplyr::any_of(c("coi_method", "optimization", "COI")),
    .after = name
  )
```

We can next plot all our estimates and further include the deviation from the
median THE REAL McCOIL estimation.

```{r result figure}
panela <- ggplot(
  data = dplyr::filter(pivot_data, coi_method == "var"),
  mapping = aes(y = COI, x = rmcl_med, color = optimization)
) +
  scale_size_area() +
  geom_abline(color = "gray", size = 0.5) +
  geom_count(alpha = 0.8, position = position_jitter(width = 0.1)) +
  theme_coiaf() +
  labs(
    title = "Variant Method",
    y = "coiaf Prediction",
    color = "Optimization Method"
  ) +
  scale_color_discrete(labels = c("Continuous", "Discrete")) +
  guides(size = "none") +
  scale_x_continuous("THE REAL McCOIL Prediction", breaks = seq(0, 10))

panelb <- ggplot(
  data = dplyr::filter(pivot_data, coi_method == "freq"),
  mapping = aes(y = COI, x = rmcl_med, color = optimization)
) +
  scale_size_area() +
  geom_abline(color = "gray", size = 0.5) +
  ggplot2::geom_count(alpha = 0.8, position = position_jitter(width = 0.1)) +
  theme_coiaf() +
  labs(
    title = "Frequency Method",
    y = "coiaf Prediction",
    color = "Optimization Method"
  ) +
  scale_color_discrete(labels = c("Continuous", "Discrete")) +
  guides(size = "none") +
  scale_x_continuous("THE REAL McCOIL Prediction", breaks = seq(0, 10))

panelc <- ggplot(pivot_data, aes(x = COI - rmcl_med, fill = coi_method)) +
  geom_density(alpha = 0.6) +
  labs(x = "COI - Median RMCL", y = "Density", fill = "COI Method") +
  scale_fill_discrete(labels = c("Variant", "Frequency")) +
  theme_coiaf() +
  theme(legend.position = "right")

# Use patchwork to make life easier
patchwork <- (panela / panelb) | panelc
patchwork +
  plot_annotation(tag_levels = "A") +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")
```

## World Maps

### Pf6k Data

We need to access the Pf6k data in order to create a world map.

```{r read Pf6k, eval = read_pf6k}
# Read in
temp_file <- tempfile()
download.file(
  "ftp://ngs.sanger.ac.uk/production/malaria/pfcommunityproject/Pf6/Pf_6_samples.txt",
  temp_file
)
meta <- data.table::fread(temp_file)
saveRDS(meta, file = "analysis/pf6k_meta.rds")
```

```{r load Pf6k, eval = !read_pf6k, include = FALSE}
meta <- readRDS("analysis/pf6k_meta.rds")
```

We can then cluster our samples into suitably close regions, for which we assume
the same PLAF exists but without reducing our n. We can use a silhouette plot to
visualize the optimum number of regions to guide our decisions.

```{r k-means}
# K Means
locations <- unique(meta[, c("Lat", "Long")])

sis <- 2:(nrow(locations) - 1)
for (k in sis) {
  si <- cluster::silhouette(cluster::pam(x = locations, k))
  sis[k - 1] <- mean(si[, 3])
}

# Silhouette plot
# N.B. element_line throws a warning when give it a list as an input. A
# workaround for this for making the number a different color is to use
# `ggtext::element_markdown`, but this does not work for making the tick mark
# another color
sil <- data.frame(
  cluster = seq_along(sis) + 1,
  sis = sis
)
ggplot(sil, aes(x = cluster, y = sis)) +
  geom_point() +
  geom_vline(xintercept = which(diff(sign(diff(sis))) == -2) + 2, linetype = 5) +
  geom_vline(xintercept = 24, linetype = 5, color = "red") +
  annotation_custom(
    grob = grid::segmentsGrob(gp = grid::gpar(col = "red", lwd = 2)),
    xmin = 24, xmax = 24, ymin = -0.025, ymax = -0.02
  ) +
  scale_x_continuous(breaks = c(0, 20, 24, 40, 60)) +
  labs(x = "Number of Clusters", y = "Average Silhoutte Score") +
  theme_coiaf() +
  theme(
    axis.title = element_text(size = 8),
    axis.text.x = ggtext::element_markdown(color = c("black", "black", "red", "black", "black")),
    axis.ticks.x = element_line(color = c("black", "black", "red", "black", "black"))
  )
```

Based on this plot, we select 24 regions as the optimal cluster number. We then
cluster our samples and combine the data with our predictions.

```{r cluster}
# Clustering with 24 locations
ks <- cluster::pam(meta[, c("Lat", "Long")], k = 24)
meta$color <- as.factor(ks$clustering)
```

We may also be interested in the prevalence of malaria in various regions.
```{r prevalence data}
# Get the lat longs
coords <- data.frame(meta$Long, meta$Lat)
names(coords) <- c("x", "y")

# make column for 2-10 year old prevalence
meta$prev_2_10 <- as.numeric(meta$Year)
meta <- tidyr::drop_na(meta)

# get rasters using malariaAtlas package (this will take like 15 mins to download)
PfPR2_10 <- malariaAtlas::getRaster(year = sort(unique(meta$prev_2_10)))

# loop through and extra malaria prevalence
for (i in seq_along(sort(unique(meta$Year)))) {
  year <- sort(unique(meta$Year))[i]
  pos <- which(meta$Year == year)
  i_coords <- coords[pos, ]
  prev <- raster::extract(PfPR2_10[[i]], i_coords)
  meta$prev_2_10[pos] <- prev
}

# Store FwS data
fws <- read.csv("ftp://ngs.sanger.ac.uk/production/malaria/pfcommunityproject/Pf6/Pf_6_fws.txt", sep = "\t")

# Combine Pf6k, FwS, and our predictions
patient_lat_long <- dplyr::left_join(
  compare_data, meta,
  by = c("name" = "Sample")
) %>%
  dplyr::left_join(fws, by = c("name" = "Sample"))
```


### Plotting

World map with average COI

```{r world map, fig.height = 2}
# Get average of data
map_average <- patient_lat_long %>%
  dplyr::group_by(Site, Lat, Long) %>%
  dplyr::summarise(
    coi_mean = mean(dis_var_med),
    coi_med = median(dis_freq_med),
    prev = median(as.numeric(prev_2_10)),
    rmcl_med = median(rmcl_med),
    .groups = "drop"
  ) %>%
  dplyr::rename(lat = Lat) %>%
  dplyr::rename(long = Long)

# Plot the mean COI
mean_world <- world_map(
  map_average,
  coi_mean,
  label = "Mean COI",
  alpha = 0.7,
  breaks = c(1.0, 1.5, 2.0, 2.5)
)
mean_world

# Plot the median COI
med_world <- world_map(
  map_average,
  coi_med,
  label = "Median COI",
  alpha = 0.7,
  breaks = c(1.0, 1.5, 2.0)
)
med_world
```

World map with all data

```{r all patients map, fig.height = 2}
# Get data that has a COI of less than 10. This is done for now as we suspect
# there are some samples that are wrong! Regions that predict 25!
# The two patients are: "PN0075-C" and "PT0069-C"
# We also set up data to be descending so that smaller COIs stay on top.
all_world_map <- patient_lat_long %>%
  dplyr::filter(dis_var_med <= 10) %>%
  dplyr::arrange(desc(dis_var_med)) %>%
  dplyr::rename(lat = Lat) %>%
  dplyr::rename(long = Long)

# Plot all patient COIs (theme is added so that there is less whitespace)
all_world <- world_map(
  all_world_map,
  dis_var_med,
  "COI",
  alpha = 0.7,
  breaks = c(1, 2, 4, 6, 8, 10)
)
all_world
```

### Prevalence & FwS

```{r prevalence and fws}
prev_fws <- patient_lat_long %>%
  tidyr::pivot_longer(dplyr::any_of(c("cont_var_med", "rmcl_med")),
    names_to = "Method",
    values_to = "COI",
    values_drop_na = TRUE
  ) %>%
  dplyr::select(name, Region:Long, prev_2_10:COI) %>%
  dplyr::mutate(
    prev = as.numeric(prev_2_10),
    Method = dplyr::recode(
      Method,
      cont_var_med = "Continuous Method 1",
      rmcl_med = "THE REAL McCOIL"
    ),
    .keep = "unused"
  )

grouped <- prev_fws %>%
  dplyr::group_by(prev, Method) %>%
  dplyr::summarise(
    COI = median(COI),
    Fws = median(Fws),
    .groups = "drop"
  )

# FwS
ggplot(data = grouped, aes(x = Fws, y = COI, color = Method)) +
  geom_point(alpha = 0.3, position = position_jitter(height = 0.2)) +
  labs(x = "FwS", y = "Estimated COI") +
  facet_grid(~Method) +
  scale_color_discrete(
    name = "Estimation Method",
    labels = c("Discrete Method 1", "THE REAL McCOIL")
  ) +
  theme_coiaf()

# Prevalence
ggplot(data = grouped, aes(x = prev, y = COI, color = Method)) +
  geom_point(alpha = 0.3, position = position_jitter(height = 0.2)) +
  scale_x_log10(
    breaks = c(0.01, 0.1, 1),
    labels = c(0.01, 0.1, 1),
    limits = c(0.01, 1)
  ) +
  facet_grid(~Method) +
  labs(x = "Log10 Prevalence", y = "Estimated COI") +
  scale_color_discrete(
    name = "Estimation Method",
    labels = c("Continuous Method 1", "THE REAL McCOIL")
  ) +
  theme_coiaf()

ggplot(
  data = tidyr::drop_na(grouped),
  aes(
    x = cut(prev, seq(0, 1, 0.1), right = TRUE),
    y = COI, color = Method
  )
) +
  geom_boxplot(alpha = 0.3) +
  facet_grid(~Method) +
  labs(x = "Prevalence", y = "Estimated COI") +
  scale_color_discrete(
    name = "Estimation Method",
    labels = c("Continuous Method 1", "THE REAL McCOIL")
  ) +
  theme_coiaf()
```

### A Different Visualization

```{r prevalence}
filter_data <- patient_lat_long %>%
  tidyr::pivot_longer(
    cols = dplyr::starts_with(c("dis", "cont")),
    names_to = c(".value", "coi_method"),
    names_pattern = "(.*)_(.*)_.*"
  ) %>%
  tidyr::pivot_longer(
    cols = dplyr::any_of(c("dis", "cont")),
    names_to = "optimization",
    values_to = "COI",
    values_drop_na = TRUE
  ) %>%
  dplyr::relocate(
    dplyr::any_of(c("coi_method", "optimization", "COI")),
    .after = name
  ) %>%
  dplyr::filter(coi_method == "var" & optimization == "dis")

continents <- filter_data %>%
  dplyr::group_by(Region) %>%
  dplyr::mutate(med_prev = median(prev_2_10, na.rm = TRUE)) %>%
  dplyr::filter(med_prev != 0) %>%
  dplyr::arrange(prev_2_10) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(
    Region = forcats::as_factor(Region),
    continent = countrycode::countrycode(Country, "country.name", "continent")
  )

sorted_prev <- continents %>%
  dplyr::select(Region, med_prev) %>%
  dplyr::distinct() %>%
  dplyr::pull(med_prev) %>%
  sort()

ridges <- ggplot(
  data = tt,
  aes(y = forcats::fct_reorder(Region, med_prev), x = COI, fill = continent)
) +
  ggridges::geom_density_ridges() +
  ggridges::theme_ridges() +
  theme_coiaf() +
  scale_fill_viridis_d(name = "Continent") +
  annotate(
    "text",
    x = 6.25,
    y = 1:16 + 0.3,
    label = round(sorted_prev, 2),
    size = 2.5
  ) +
  labs(x = "COI", y = "Region")
```

```{r patchwork}
mean_world / med_world / ridges +
  plot_annotation(tag_levels = "A") +
  plot_layout(widths = c(2, 2, 1))
```
