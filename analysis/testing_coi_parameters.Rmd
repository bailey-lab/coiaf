---
title: "Testing COI Parameters"
author: "Aris Paschalidis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
    fig_caption: yes
editor_options:
  chunk_output_type: console
---

```{r imports, echo=F, warning=F, message=F, results='hide'}
library(coiaf)
```

In this analysis file, we aim to understand the effect of varying parameters on
our COI framework. The parameters that we will examine are:

* COI_range: A number indicating the range of COIs to compare the simulated 
data to.
* coverage: Coverage at each locus.
* alpha: Shape parameter of the symmetric Dirichlet prior on strain proportions.
* overdispersion: The extent to which counts are over-dispersed relative to the 
binomial distribution. Counts are Beta-binomially distributed, with the beta 
distribution having shape parameters $p/overdispersion$ and 
$(1-p)/overdispersion$.
* epsilon: The probability of a single read being miscalled as the other allele.
Applies in both directions.
* seq_error: The level of sequencing error that is assumed.
* method: The method to be employed. One of "end", "ideal", "overall".
* dist_method: The distance method used to determine the distance between the 
theoretical and simulated curves for the "overall" method. One of "abs_sum", 
"sum_abs", "squared", "KL".
* weighted: An indicator indicating whether to compute weighted distance.

#### Setting our PLAF
```{r}
# set seed
set.seed(1)

# Define number of loci, and distribution of minor allele frequencies
L <- 1e3
p <- rbeta(L, 1, 5)
p[p > 0.5] <- 1 - p[p > 0.5]
```

## COI
We first want to understand for what range our model can accurately predict
the COI.

```{r}
test <- coi_test(COI = 2:20, repetitions = 100,
                 PLAF = p, method = "overall", dist_method = "squared")
test$error_bias
```

Based on the above set of runs, it appears that for a COI of greater than 9, the
error and bias start to increase quite rapidly. At a COI of 10, if one were to
look at the predicted COI values, it becomes immediatl clear that our process
of calculating the COI fails. The predicted COIs have a very large range and
very often, the predicted COI value will be zero. In addition, the mean is
roughly 5, very far away from the actual COI of ten. In fact, for all COIs 10 or
greater, the mean COI is very far away from the true COI value.

## COI Range
```{r}
test <- coi_test(COI = 2:20, COI_range = 10:20, repetitions = 100,
                 PLAF = p, method = "overall", dist_method = "squared")
test$error_bias
```

As expected, the lower the COI range, the lower the error and bias. This makes
intuitive sense as the COI_range allows us to determine how many theoretical
COI values we will test to see which our simulated data is closest to. The fact
that our model works well with large `COI_range` values is promising and implies
that our model can accuratly compute the COI.

## Coverage
```{r}
test <- coi_test(COI = 2:20, coverage = c(25, 50, 100, 200, 400), 
                 repetitions = 100, PLAF = p,
                 method = "overall", dist_method = "squared")
test$error_bias
```

## Alpha
```{r}
test <- coi_test(COI = 2:20, alpha = 1:10, 
                 repetitions = 100, PLAF = p, 
                 method = "overall", dist_method = "squared")
test$error_bias
```

## Overdispersion
```{r}
test <- coi_test(COI = 2:20, overdispersion = seq(0, 0.1, 0.05), 
                 repetitions = 100, PLAF = p, 
                 method = "overall", dist_method = "squared")
test$error_bias
```

When you introduce overdispersion, models perform poorly. If you introduce 0.1, 
models do not perform terribly. What is the cutoff here? How much overdispersion
can we introduce?

## Epsilon
```{r}
test <- coi_test(COI = 2:20, epsilon = seq(0, 1, 0.1), 
                 repetitions = 100, PLAF = p, 
                 method = "overall", dist_method = "squared")
test$error_bias
```

## Sequencing Error
```{r}
test <- coi_test(COI = 2:20, seq_error = seq(0, 0.1, 0.02), 
                 repetitions = 100, PLAF = p, 
                 method = "overall", dist_method = "squared")
test$error_bias
```

## Method
```{r}
test <- coi_test(COI = 2:20, PLAF = p, dist_method = "squared", 
                 repetitions = 100)
test$error_bias
```


## Distance Method
```{r}
test <- coi_test(COI = 2:20, PLAF = p, method = "overall", repetitions = 100)
test$error_bias
```

## Weighted
```{r}
test <- coi_test(COI = 2:20, weighted = c(FALSE, TRUE),
                 PLAF = p, method = "overall", repetitions = 100)
test$error_bias
```
