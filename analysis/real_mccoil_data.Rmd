---
title: "REAL McCOIL Data"
author: "Aris Paschalidis"
date: "`r format(Sys.time(), '%B %Y')`"
output:
  html_document:
    highlight: pygments
    toc: true
    toc_float: true
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
# Here, we set default options for our markdown file
knitr::opts_chunk$set(
  comment = "#>"
)
# Change the way tibble prints so only prints 5 extra columns
options(tibble.max_extra_cols = 5)

# Function to determine if pbapply is installed. If it is installed, it will
# display a progress bar
list_apply <- function(x, fun, ...){
  if (requireNamespace("pbapply", quietly = TRUE)) {
    pbapply::pblapply(x, fun, ...)
    } else {
    lapply(x, fun, ...)
  }
}

# Define booleans to determine whether certain code chunks should be run.
run_real = FALSE
read_pf3k = FALSE

library(coiaf)
library(ggplot2)
```

In this analysis file, we run our COI algorithm on a collection of real data
obtained from the Pf3k Malaria project. Additionally, we compare the results of
our algorithm with the current state of the art model for predicting COI -- REAL
McCOIL.

## Run Real Data

```{r read data}
# Path to data
path = "~/Desktop/Malaria/COI data/"

# Read in the real data and the REAL McCOIL COI predictions
rmcl_wsafs   <- readRDS(paste0(path, "RMCL_wsafs_unique.rds"))
rmcl_coi_out <- readRDS(paste0(path, "RMCL_coi_out.rds")) %>% 
  tibble::as_tibble() %>% 
  dplyr::mutate(dplyr::across(c(file, name), as.character)) %>% 
  dplyr::rename(rmcl = COI) %>% 
  dplyr::rename(rmcl_025 = COI_025) %>% 
  dplyr::rename(rmcl_975 = COI_975)
```

Run our data, set it up in an ideal format and save the data sets as .rds files.

```{r run data, eval = run_real}
# seq(1, length(rmcl_wsafs), 10)
raw_predictions <-  pbapply::pblapply(seq_len(length(rmcl_wsafs)), function(x) {
  print(names(rmcl_wsafs)[x])
  sample <- rmcl_wsafs[[x]]
  plaf   <- colMeans(sample, na.rm = T)
  
  # For each sample run the optimize_coi function
  coi_region <- pbapply::pblapply(seq_len(nrow(sample)), function(i) {
    wsaf  <- sample[i,]
    input <- tibble::tibble(wsaf = wsaf, plaf = plaf) %>% tidyr::drop_na()
    
    ## Compute COI
    # Discrete
    rob_d1 <- function(input) {
      tryCatch(discrete_1 <- compute_coi(input, "real", coi_method = "1", bin_size = 50)$coi, 
             error = function(e) {print(paste("Error for sample", rownames(sample)[i])); NaN})
    }
    discrete_1 <- rob_d1(input)
    rob_d2 <- function(input) {
      tryCatch(discrete_2 <- compute_coi(input, "real", coi_method = "2", bin_size = 50)$coi, 
             error = function(e) {print(paste("Error for sample", rownames(sample)[i])); NaN})
    }
    discrete_2 <- rob_d2(input)

    # Continuous
    rob_c1 <- function(input) {
      tryCatch(continuous_1 <- optimize_coi(input, "real", coi_method = "1", bin_size = 50), 
             error = function(e) {print(paste("Error for sample", rownames(sample)[i])); NaN})
    }
    continuous_1 <- rob_c1(input)
    rob_c2 <- function(input) {
      tryCatch(continuous_2 <- optimize_coi(input, "real", coi_method = "2", bin_size = 50), 
             error = function(e) {print(paste("Error for sample", rownames(sample)[i])); NaN})
    }
    continuous_2 <- rob_c2(input)
    # continuous_1 <- optimize_coi(input, "real", coi_method = "1")
    # continuous_2 <- optimize_coi(input, "real", coi_method = "2")

    # coi_region <- discrete_1
    coi_region <- list(discrete_1 = discrete_1, discrete_2 = discrete_2,
                       continuous_1 = continuous_1, continuous_2 = continuous_2)

  }) %>% unlist()
  coi_region <- split(unlist(coi_region), names(coi_region))
  
  # Prediction tibble
  pred <- tibble::tibble(name = rownames(sample),
                         discrete_1 = coi_region$discrete_1,
                         discrete_2 = coi_region$discrete_2,
                         continuous_1 = coi_region$continuous_1,
                         continuous_2 = coi_region$continuous_2,
                         file = names(rmcl_wsafs)[x])
  # pred <- tibble::tibble(name = rownames(sample),
                         # discrete_1 = coi_region,
                         # file = names(rmcl_wsafs)[x])

  # Summarize over the 5 rmcl runs
  rmcl_outputs <- rmcl_coi_out %>%
    dplyr::filter(stringr::str_detect(file, names(rmcl_wsafs)[x])) %>%
    dplyr::group_by(name) %>%
    dplyr::summarise(rmcl_med     = median(rmcl),
                     rmcl_025_med = median(rmcl_025),
                     rmcl_975_med = median(rmcl_975),
                     .groups = "drop") 

  # Join the tibbles
  combined <-  dplyr::full_join(pred, rmcl_outputs, by = "name") %>% 
    dplyr::mutate(Region = as.numeric(stringr::str_extract(file, "(?<=region_)[:digit:]*"))) %>% 
    dplyr::mutate(VCF = as.numeric(stringr::str_extract(file, "(?<=vcf_)[:digit:]*"))) %>% 
    dplyr::relocate(file, .after = dplyr::last_col())

})
names(raw_predictions) <- names(rmcl_wsafs)

# Set up a tibble with all the information from the runs. Summarize over the 10
# VCFs
complete_predictions <- raw_predictions %>%
  dplyr::bind_rows() %>% 
  dplyr::group_by(name, Region) %>% 
  dplyr::summarise(discrete_1_med   = median(discrete_1),
                   discrete_2_med   = median(discrete_2),
                   continuous_1_med = median(continuous_1),
                   continuous_2_med = median(continuous_2),
                   rmcl_med         = median(rmcl_med),
                   rmcl_025_med     = median(rmcl_025_med),
                   rmcl_975_med     = median(rmcl_975_med),
                   .groups = "drop") %>% 
  dplyr::relocate(Region, .after = dplyr::last_col())

# Save data
saveRDS(raw_predictions, file = "analysis/rmcl_raw_predictions.rds")
saveRDS(complete_predictions, file = "analysis/rmcl_complete_predictions.rds")
```

```{r load data, eval = !run_real, include = FALSE}
raw_predictions_old <- readRDS("analysis/rmcl_raw_predictions_old.rds")
complete_predictions_old <- readRDS("analysis/rmcl_complete_predictions_old.rds")
```

We want to make sure that we have tested all the patients, so we can look at
our three data structures and ensure that the number of patients is the same
for all.
```{r number of patients}
# According to our predictions
length(unique(complete_predictions$name))

# According to rmcl output
length(unique(rmcl_coi_out$name))

# According to WSAFs
wsafs_patients <- lapply(seq_len(length(rmcl_wsafs)), function(x) {
  rownames(rmcl_wsafs[[x]])
})
wsafs_patients %>% unlist() %>% unique() %>% length()
```
Looking at these values, we can see that for our WSAF matrices and our 
predictions the number of patients match. However, our rmcl output has fewer
total patients. We need to be sure to exclude these whenw we are comparing our
two methods.

## Evaluate Our Predictions

We want to be sure to exclude all samples for which we do not have a rmcl
estimate.
```{r exclude patients}
exclude <- setdiff(unique(complete_predictions$name), unique(rmcl_coi_out$name))
compare_data <- complete_predictions %>% 
  dplyr::filter(! name %in% exclude) %>% 
  dplyr::mutate(diff_med = pred_med - rmcl_med) %>% 
  dplyr::mutate(in_CI = ifelse(pred_med >= rmcl_025_med & 
                                 pred_med <= rmcl_975_med, 1, 0)) %>% 
  dplyr::relocate(Region, .after = dplyr::last_col())
```

Plot the results looking at COI and comparison to REAL McCOIL.

```{r predicted COI plot}
num_breaks <- function(x) floor(seq(0, max(x), length.out = 5))

ggplot(compare_data, aes(pred_med)) +
  geom_density(fill = "gray", alpha = 0.3) + 
  facet_wrap(. ~ Region, nrow = 4, scales = "free", labeller = "label_both") +
  scale_x_continuous(breaks = num_breaks) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 13),
        axis.title = element_text(size = 10)) +
  guides(fill = FALSE) +
  labs(x = "Predicted COI", y = "Density", 
       title = "Predicted COI in Each Region")
```

```{r median coiaf vs REAL McCOIL}
num_breaks_v2 <- function(x) round(seq(min(x), max(x), length.out = 5))

ggplot(compare_data, aes(diff_med)) +
  geom_density(fill = "gray", alpha = 0.3) +
  facet_wrap(. ~ Region, nrow = 4, scales = "free", labeller = "label_both") + 
  theme_classic() +
  scale_x_continuous(breaks = num_breaks_v2) +
  theme(plot.title  = element_text(hjust = 0.5, size = 13),
        axis.title = element_text(size = 10)) +
  guides(fill = FALSE) +
  labs(x = "Difference Between coiaf And REAL McCOIL Median", y = "Density", 
       title = "Difference Between coiaf And REAL McCOIL Median By Region")
```

### Incorrect Trends
Why does our model get samples wrong?

```{r, eval = FALSE}
# Convert continuous result to discrete result
enhanced <- compare_data %>% 
  dplyr::mutate(round = ifelse(pred_med - floor(pred_med) >= 0.2, 
                             ceiling(pred_med),
                             floor(pred_med))) %>% 
  dplyr::relocate(round, .after = pred_med)

incorrect <- enhanced %>% 
  dplyr::filter(round != rmcl_med) %>% 
  dplyr::arrange(pred_med)

# Make sure PLAF is less than 0.5. This is done in process real. Plot a specific
# sample
plot(colMeans(rmcl_wsafs$cat_region_21_vcf_0, na.rm = T) %>% 
  ifelse(. > 0.5, 1 - ., .),
     rmcl_wsafs$cat_region_21_vcf_0["PV0091-C",],
  main = "Opt = 1.20035, RMCL = 1")
```


## World Maps

### Pf3k Data

We need to access the Pf3k data in order to create a world map. 

```{r read Pf3k, eval = read_pf3k}
# Read in
tf <- tempfile()
download.file("ftp://ngs.sanger.ac.uk/production/malaria/pfcommunityproject/Pf6/Pf_6_samples.txt",tf)
meta <- data.table::fread(tf)
saveRDS(meta, file = "analysis/pf3k_meta.rds")
```

```{r load Pf3k, eval = !read_pf3k, include = FALSE}
meta <- readRDS("pf3k_meta.rds")
```

We can then cluster our samples into suitably close regions, for which we assume
the same PLAF exists but without reducing our n. We can use a silhouette plot to 
visualize the optimum number of regions to guide our decisions.

```{r k-means}
# K Means
locations <- unique(meta[, c("Lat", "Long")])

sis <- 2:(nrow(locations) - 1)
for(k in sis) {
  si <- cluster::silhouette(cluster::pam(x = locations, k))
  sis[k - 1] <- mean(si[, 3])
}

par(mfrow = c(1,1))
plot(sis)
abline(v = which(diff(sign(diff(sis))) == -2) + 1)
text(which(diff(sign(diff(sis))) == -2) + 2, 0.1, 
     which(diff(sign(diff(sis)))== -2) + 2)
```

Based on this plot, we select 24 regions as the optimal cluster number. We then
cluster our samples and combine the data with our predictions.

```{r cluster}
# Clustering with 24 locations
ks <- cluster::pam(meta[,c("Lat","Long")], k = 24)
meta$color <- as.factor(ks$clustering)

# Combine Pf3k and our predictions
patient_lat_long <- dplyr::left_join(complete_predictions, meta, 
                                     by = c("name" = "Sample")) 
```

### Plotting

World map with average COI

```{r world map, fig.height = 2}
# Get average of data
map_average <- patient_lat_long %>% 
  dplyr::group_by(color) %>% 
  dplyr::summarise(lat = mean(Lat),
                   long = mean(Long), 
                   coi_mean = mean(pred_med),
                   coi_med = median(pred_med), 
                   .groups = "drop")

# Plot the mean COI
print(world_map(map_average, map_average$coi_mean, label = "Mean COI", 
                alpha = 1, breaks = c(1.0, 1.5, 2.0, 2.5)))

# Plot the median COI
print(world_map(map_average, map_average$coi_med, label = "Median COI", 
                alpha = 1, breaks = c(1.0, 1.5, 2.0)))
```

World map with all data

```{r all patients map, fig.height = 2}
# Get data that has a COI of less than 10. This is done for now as we suspect
# there are some samples that are wrong! Regions that predict 25! 
# The two patients are: "PN0075-C" and "PT0069-C"
# We also set up data to be descending so that smaller COIs stay on top.
all_world_map <- patient_lat_long %>% 
  dplyr::filter(pred_med <= 10) %>% 
  dplyr::arrange(desc(pred_med)) %>% 
  dplyr::rename(lat = Lat) %>% 
  dplyr::rename(long = Long)

# Plot all patient COIs (theme is added so that there is less whitespace)
print(world_map(all_world_map, all_world_map$pred_med, "COI", 
                breaks = c(1, 2, 4, 6, 8, 10)))
```

